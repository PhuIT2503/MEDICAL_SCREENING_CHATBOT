{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aiCK_ChgQ5Z",
        "outputId": "8eae7003-be35-486a-a977-fd4e5ff5aeed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.11.12)\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-8.3.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from underthesea) (8.3.1)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.12/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from underthesea) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from underthesea) (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from underthesea) (6.0.3)\n",
            "Collecting underthesea_core==1.0.5 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from underthesea) (0.36.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8->underthesea) (2025.11.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2025.11.12)\n",
            "Downloading underthesea-8.3.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.4/978.4 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea_core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-8.3.0 underthesea_core-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install transformer datasets torch pandas\n",
        "!pip install tokenizers\n",
        "!pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADfol03TlClg",
        "outputId": "10401190-1096-4e3e-be03-495ff3ad2f0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã lưu file train với kích thước 581\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "# Đọc file Excel chứa dữ liệu bệnh và triệu chứng\n",
        "try:\n",
        "    df = pd.read_excel(\"./data/DataBase.xlsx\")\n",
        "except:\n",
        "    print(\"Thiếu file hoặc sai đường dẫn file\")\n",
        "\n",
        "# Hàm tiền xử lý text\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    - Kiểm tra NaN, trả về chuỗi rỗng nếu NaN\n",
        "    - Chuyển text về dạng string\n",
        "    - Xóa ký tự \\\n",
        "    - Thay xuống dòng (\\n, \\r) bằng khoảng trắng\n",
        "    - Xóa khoảng trắng thừa\n",
        "    - Tách từ tiếng Việt bằng underthesea\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    text = str(text)\n",
        "    text = re.sub(r'\\\\', '', text)                      # xóa ký tự \\\n",
        "    text = text.replace('\\n', ' ').replace('\\r', ' ')  # thay xuống dòng bằng space\n",
        "    text = re.sub(' +', ' ', text)                      # loại khoảng trắng thừa\n",
        "\n",
        "    # tách từ tiếng Việt\n",
        "    text_segment = word_tokenize(text, format=\"text\")\n",
        "    return text_segment\n",
        "\n",
        "# Kiểm tra cột \"Triệu chứng\" tồn tại\n",
        "if \"Triệu chứng\" in df.columns:\n",
        "    # Tạo cột content ghép tên bệnh + triệu chứng\n",
        "    df['content'] = df[\"Tên bệnh\"] + \" có triệu chứng là \" + df[\"Triệu chứng\"]\n",
        "\n",
        "    # Tiền xử lý từng dòng\n",
        "    symptoms = df[\"content\"].apply(clean_text)\n",
        "\n",
        "    # Loại bỏ dòng rỗng\n",
        "    symptoms = symptoms[symptoms != \"\"]\n",
        "\n",
        "    # Lưu kết quả vào file txt, mỗi dòng là 1 văn bản\n",
        "    with open(\"./data/symptoms_train.txt\", \"w\", encoding='utf-8') as f:\n",
        "        for line in symptoms:\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "    print(f\"Đã lưu file train với kích thước {len(symptoms)}\")\n",
        "\n",
        "else:\n",
        "    print(\"Không tìm thấy cột triệu chứng\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1a29afa71eb7499c9e3d3860b27f9f35",
            "58fe6f29a325466bafd10551bb1749cf",
            "d08fddc1a5834e3e821fea30f14613b4",
            "c4515cca395f494c8af60d835ccba1df",
            "8b11198b1f764e67bef36d784a5a323c",
            "9625704d1b924b44a9fe85f57c4e8a2e",
            "9440930d9c0542e59b58189d85999b5b",
            "cbca713f5c364642b84ab1b3f4676471",
            "afcb350d00f343b2a31743555eda7d7c",
            "425c99466bf9493f9702b533d9e15f8d",
            "99b162a159224275a262092f1e3cca09",
            "614625f794804cb19ce33c5f534a81f6",
            "bce749f416dc4f92be4e0acd07d313d0",
            "24db43b964fe45d7ad85ce73fd9d8286",
            "2dd0b6262e85464d826439c656578b9a",
            "5ccc1c410bda4959882c215b485a0ae8",
            "d9881fc7fb104705b0eb2bce967d005d",
            "b213c2474d97476daf1d228670b8da6d",
            "00b316a9dd82413babe9002a222b4383",
            "00c6c53af28745d498ac325b21ad3c50",
            "47333aaccf4f48c1a98c56d47766ba46",
            "b3c9af92cb1d428a9bd1911f4ce452d5",
            "0c374057e6e2449992af18fc5409d021",
            "693166794cd04efeadac6b0cd0dca37a",
            "df6a0b4e06b945318523e648ea96946e",
            "3a337b39d0774f4ea9f76f62818e70bb",
            "613511d1edcf4ef6a259f23099e1fc64",
            "e3c2f770919743de967e81110b432978",
            "f441591dbdd245b88c207eb81f7d0b1a",
            "bf4469bf831249bea6a1d76fc8245b31",
            "9b7c65d568874901b07b13f0fd4e777a",
            "bf282d98b38c4962bc61dbd63b8b7600",
            "dc475c98c2214b7aa940b599d72221e9",
            "5f317b30042b405197d9f42d31fe785a",
            "5845b3ce9c084939bb5c84e6e183a7ff",
            "d57800b5c61b47e4ad51866656cc107f",
            "c5caa8a24f3f4fb78fa4c4e3481050f6",
            "24ee80efdfcc4ca68ff37ba27adcbf0e",
            "211f72b3ecc349e99dc183feaf9fdf19",
            "82c1c5346b154d02bd9e3a2836322094",
            "540449c15ce44345844ca48d34deadce",
            "91d1397f60d5495c9d9faedeab185a5d",
            "fe1bf9478d984d208a228fdbde609888",
            "2be481c3fba947ff829ced17b16e5ba9",
            "1b02d69216a24ee69eb8bc456c4ce86a",
            "80ac0121f10a42499cfcc0340d9d6992",
            "75938a6f32ee4d9a8671dd562e9dd80f",
            "144d5dc719e5419283fc1268222b09b4",
            "2fb7ff3521cc413d8bb6d392cdd78c77",
            "355ea30373eb4cfa9bf1e9dafa1b1d12",
            "9dcac8a586be4c76a57838d55ec9455a",
            "a0f7414b6a134e59b6004b0689d8f30e",
            "14d9494f8499432b92322212ad0b0caa",
            "8ef33393b8db45099fcfdb1f6abb3abe",
            "30125f55eac84400984e741934960c91",
            "73c8e14759a34bcbaf5d442ef9885070",
            "22a505e47a4e4ef09c91d941a8a2a673",
            "b39aea18a1dc4f539a71476ef4a38cc8",
            "da75204b1576423bb08c912b3e216903",
            "d03cee3b9816493ea5cd7bbbaa78840a",
            "0b4cd055824649d2823425fcc65ca852",
            "28bf24e06dcc4ce7b2985917941a9b8e",
            "d153bc2a687a458293dddfdc97a53cfb",
            "d3528698e15045a78944ff5826c6b5d1",
            "e21abefd8e8245faa25349aef45c26c3",
            "106f4af8dbfd48d78086b7d09bc3069f",
            "ddb6412316bb4462a4bc5c782f707fc2",
            "71facea68de64e25b216ae6a97356460",
            "1bd9349a1458403f8c8688cef2a42f5a",
            "21c48609294c4e8fbe3fd38dd1fd6c26",
            "f7fb7e3403f74dfa91bc7b6b32f2b439",
            "023d06d94906452aadfdf0c683a1f451",
            "d39fb71af6f741e89c67e0e0a0380b80",
            "e46780d977a0400ebb0c122483bfa9ea",
            "b4e34304acf8448696d0dcd23e193cf9",
            "fb2f94cb08e34a528830630856348cde",
            "77b53b340fd64bfea900a0ae039df12c"
          ]
        },
        "id": "Xxbzr7g9p4SG",
        "outputId": "fdd87724-a6c7-40ec-ba5c-f7e20c695237"
      },
      "outputs": [],
      "source": [
        "from transformers import PhobertTokenizer, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load tokenizer PhoBERT\n",
        "tokenizer = PhobertTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenize các văn bản đầu vào:\n",
        "      - examples[\"text\"] là list các string\n",
        "      - truncation=True để cắt dài quá max_length\n",
        "      - max_length=256 token\n",
        "    \"\"\"\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=256)\n",
        "\n",
        "# Load dataset từ file txt\n",
        "raw_datasets = load_dataset(\n",
        "    'text',\n",
        "    data_files={'data': './data/symptoms_train.txt'}  # file txt train\n",
        ")\n",
        "\n",
        "# Chia train và test (90% train và 10% test)\n",
        "split_datasets = raw_datasets[\"data\"].train_test_split(\n",
        "    test_size=0.1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Tokenize và loại bỏ cột gốc \"text\"\n",
        "train_dataset = split_datasets[\"train\"].map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "test_dataset = split_datasets[\"test\"].map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "print(f\"Số lượng mẫu train: {len(train_dataset)}\")\n",
        "print(f\"Số lượng mẫu test: {len(test_dataset)}\")\n",
        "\n",
        "# Data collator cho Language Modeling (MLM)\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,                 # Masked Language Modeling\n",
        "    mlm_probability=0.15      # Xác suất mask 15% token (80% token được mask, 10% giữ nguyên, 10% ngẫu nhiên tránh mô hình quá tập trung vào dự đoán token mask)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtg5lj7L1HGy",
        "outputId": "ee36eaf0-c479-45d4-a53f-5bbfb003743a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "8fd0ecd6f7b94635a1c1924b2ed211f8",
            "16031a4604d742a8bde7fa250bc6a82e",
            "925206bd4c404626ad68901426c8dd72",
            "1425745a44534e97af7267fd080cb416",
            "40fadbb1b96345e68c27eb0b78869471",
            "60357141defc4e079bd9961de49343b2",
            "4d789e33512d407ca8119fde497c2327",
            "1c6d868f77024796b06f4bf15aa85937",
            "e3496ea64de04ff69d28873ed0bac96a",
            "8ed5155f641548b3a12218a59d4a6574",
            "02ad100b475b42f79b832af439831bf3",
            "8dcb25ce7c1b4c258499d597f98981a3",
            "725b71505d0e4cccaa8cd944b7984ae6",
            "541a124b15a34431a2ead4eab11956ee",
            "9877d27f2b734e00b91afae97b07c1a6",
            "c5aa0e4e5e684c48a6d42b6effb3c2d2",
            "94cafd6d0e4e4d5b8b629834bf13a508",
            "f2859708f02342d891a8adeca1bf5256",
            "88554dcc19a248c1b3ee1d6e6c38ae44",
            "c125cfd46a4f402997fd1ef805e7262d",
            "4d70e6e8a189451ca28b9210ab13c69f",
            "c5d6fc1c968147e59246e57680717a33"
          ]
        },
        "id": "HpWphqJasC2V",
        "outputId": "9f53fab2-5022-4016-92f1-15f73245f157"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd0ecd6f7b94635a1c1924b2ed211f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/tmp/ipython-input-1550569193.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dcb25ce7c1b4c258499d597f98981a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtamphu250305\u001b[0m (\u001b[33mtamphu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251201_181619-usth9hex</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tamphu/huggingface/runs/usth9hex' target=\"_blank\">phobert-medical-final</a></strong> to <a href='https://wandb.ai/tamphu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/tamphu/huggingface' target=\"_blank\">https://wandb.ai/tamphu/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/tamphu/huggingface/runs/usth9hex' target=\"_blank\">https://wandb.ai/tamphu/huggingface/runs/usth9hex</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='198' max='198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [198/198 02:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.192400</td>\n",
              "      <td>1.975331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.116700</td>\n",
              "      <td>2.030044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.013600</td>\n",
              "      <td>1.919804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.886300</td>\n",
              "      <td>1.796645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.884400</td>\n",
              "      <td>1.785400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.860500</td>\n",
              "      <td>1.787920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Huấn luyện hoàn tất và đã lưu model\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaForMaskedLM, Trainer, TrainingArguments\n",
        "\n",
        "# Load model PhoBERT chuẩn cho Masked Language Modeling\n",
        "# Đây là model gốc, sẽ fine-tune trên dữ liệu triệu chứng y tế\n",
        "model = RobertaForMaskedLM.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "# Cấu hình training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model/phobert-medical\",   # thư mục lưu checkpoint\n",
        "    overwrite_output_dir=True,              # ghi đè nếu đã có model cũ\n",
        "    num_train_epochs=3,                     # số epoch\n",
        "    per_device_train_batch_size=8,          # batch size cho mỗi GPU/CPU\n",
        "    save_steps=500,                         # lưu checkpoint mỗi 500 step\n",
        "    save_total_limit=2,                     # giữ tối đa 2 checkpoint\n",
        "    learning_rate=2e-5,                     # learning rate\n",
        "    weight_decay=0.01,                      # weight decay cho optimizer\n",
        "    prediction_loss_only=True,              # chỉ trả loss khi eval\n",
        "    report_to=\"wandb\",                      # log tới Weights & Biases\n",
        "    run_name=\"phobert-medical-final\",       # tên experiment trên wandb\n",
        "    logging_dir=\"./logs\",                    # thư mục lưu log\n",
        "    logging_steps=30,                        # log mỗi 30 step\n",
        "    eval_strategy=\"steps\",                   # eval theo step\n",
        "    eval_steps=30                            # eval mỗi 30 step\n",
        ")\n",
        "\n",
        "# Khởi tạo Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,  # Data collator cho MLM\n",
        "    train_dataset=train_dataset,  # dataset train đã tokenize\n",
        "    eval_dataset=test_dataset,    # dataset test đã tokenize\n",
        "    tokenizer=tokenizer           # tokenizer PhoBERT\n",
        ")\n",
        "\n",
        "# Bắt đầu huấn luyện\n",
        "trainer.train()\n",
        "\n",
        "# Lưu model và tokenizer sau fine-tune\n",
        "trainer.save_model(\"./model/phobert-medical-final\")  # lưu model\n",
        "tokenizer.save_pretrained(\"./model/phobert-medical-final\")  # lưu tokenizer\n",
        "\n",
        "print(\"Huấn luyện hoàn tất và đã lưu model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RH16JmXGcPc",
        "outputId": "0c98a049-8847-422e-9397-d5b31236f7f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bệnh nhân có triệu chứng sốt cao và viêm đầu. (Score: 0.2087)\n",
            "Bệnh nhân có triệu chứng sốt cao và rối_loạn đầu. (Score: 0.0728)\n",
            "Bệnh nhân có triệu chứng sốt cao và đau đầu. (Score: 0.0639)\n",
            "Bệnh nhân có triệu chứng sốt cao và nấm đầu. (Score: 0.0504)\n",
            "Bệnh nhân có triệu chứng sốt cao và hội_chứng đầu. (Score: 0.0414)\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1) Tạo pipeline cho Masked Language Modeling\n",
        "# Sử dụng model PhoBERT đã fine-tune\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",                                # task MLM\n",
        "    model=\"./model/phobert-medical-final\",     # đường dẫn model fine-tuned\n",
        "    tokenizer=\"./model/phobert-medical-final\"  # tokenizer tương ứng\n",
        ")\n",
        "\n",
        "# Ví dụ text có token mask\n",
        "example_text = \"Bệnh nhân có triệu chứng sốt cao và <mask> đầu.\"\n",
        "\n",
        "# Dự đoán các token bị mask\n",
        "predict = fill_mask(example_text)\n",
        "\n",
        "# In kết quả dự đoánư\n",
        "for pred in predict:\n",
        "    print(f\"{pred['sequence']} (Score: {pred['score']:.4f})\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
