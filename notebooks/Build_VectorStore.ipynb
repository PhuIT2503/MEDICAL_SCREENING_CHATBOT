{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bopO9TV8Jq2Q",
        "outputId": "ab93a380-cf96-4c92-c8da-2c00010db640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-8.3.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from underthesea) (8.3.1)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.12/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from underthesea) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from underthesea) (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from underthesea) (6.0.3)\n",
            "Collecting underthesea_core==1.0.5 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from underthesea) (0.36.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8->underthesea) (2025.11.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2025.11.12)\n",
            "Downloading underthesea-8.3.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.4/978.4 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea_core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-8.3.0 underthesea_core-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TUQPJkzKPmc",
        "outputId": "5618200d-9054-46a5-f2f1-4102dfff6c2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/Luyen_Code/model/phobert-medical-final and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from underthesea import word_tokenize\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Đường dẫn đến PhoBERT đã fine-tuned\n",
        "model_path = \"./model/phobert-medical-final\"\n",
        "\n",
        "# Chọn thiết bị chạy model (GPU nếu có)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load tokenizer và model PhoBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModel.from_pretrained(model_path).to(device)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tiền xử lý văn bản:\n",
        "      - Xóa khoảng trắng thừa, xuống dòng\n",
        "      - Chuyển về lowercase\n",
        "      - Tách từ bằng underthesea\n",
        "      - Xử lý trường hợp NaN hoặc rỗng\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or not str(text).strip():\n",
        "        return ''\n",
        "\n",
        "    # Làm sạch text\n",
        "    text = str(text).lower().replace('\\n', ' ').replace('\\r', '')\n",
        "    text = re.sub(' +', ' ', text).strip()\n",
        "\n",
        "    # Tách từ bằng underthesea\n",
        "    segmented_text = word_tokenize(text, format='text')\n",
        "\n",
        "    # Nếu kết quả rỗng → trả về chuỗi rỗng\n",
        "    if not segmented_text.strip():\n",
        "        return ''\n",
        "\n",
        "    return segmented_text\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"\n",
        "    Tính embedding cho văn bản bằng kỹ thuật mean-pooling:\n",
        "      - Tokenize\n",
        "      - Lấy last_hidden_state\n",
        "      - Mean pooling dựa trên attention mask\n",
        "    Trả về: numpy vector (768 chiều đối với PhoBERT-base)\n",
        "    \"\"\"\n",
        "\n",
        "    # Tiền xử lý + tách từ\n",
        "    segmented_text = preprocess_text(text)\n",
        "\n",
        "    # Tokenize thành tensor\n",
        "    inputs = tokenizer(\n",
        "        segmented_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # Đưa tensor sang GPU nếu có\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Disable gradient cho tốc độ nhanh hơn\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_state = outputs.last_hidden_state          # (batch, seq, 768)\n",
        "    attention_mask = inputs[\"attention_mask\"]              # (batch, seq)\n",
        "\n",
        "    # Expand mask để match kích thước hidden state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "\n",
        "    # Tính tổng embedding có mask\n",
        "    sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n",
        "\n",
        "    # Mẫu số (tổng số token hợp lệ)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    # Mean pooling\n",
        "    embedding = sum_embeddings / sum_mask\n",
        "\n",
        "    # Trả về numpy vector\n",
        "    return embedding.cpu().numpy()[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEBsjSdYApgD",
        "outputId": "521af917-d318-46f1-b59c-f5458619e631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang tạo embedding....\n",
            "Đã lưu 583 vector vào Faiss\n",
            "Đã lưu file index\n",
            "Đã lưu metadata\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import pickle\n",
        "import numpy as np \n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(\"./data/DataBase.xlsx\")\n",
        "except:\n",
        "    print(\"Lỗi: Không tìm thấy file\")\n",
        "    raise SystemExit()\n",
        "\n",
        "print(\"Đang tạo embedding...\")\n",
        "\n",
        "corpus_embeddings = []   # danh sách vector embedding\n",
        "metadata = []            # danh sách metadata tương ứng\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "    content = f'{row[\"Tên bệnh\"]} có triệu chứng là {row[\"Triệu chứng\"]}'\n",
        "\n",
        "    # Tính embedding từ PhoBERT\n",
        "    vector = get_embedding(content)\n",
        "\n",
        "    # Lưu vector vào danh sách\n",
        "    corpus_embeddings.append(vector)\n",
        "\n",
        "    # Metadata tương ứng cho từng vector\n",
        "    metadata.append({\n",
        "        \"id\": index,\n",
        "        \"ten_benh\": row[\"Tên bệnh\"],\n",
        "        \"trieu_chung\": row[\"Triệu chứng\"]\n",
        "    })\n",
        "\n",
        "embedding_dim = 768   # PhoBERT-base = 768 chiều\n",
        "\n",
        "embeddings_np = np.array(corpus_embeddings).astype(\"float32\")\n",
        "\n",
        "index = faiss.IndexFlatL2(embedding_dim)   # khởi tạo faiss và dùng L2 distance\n",
        "index.add(embeddings_np)                   # thêm vector vào index\n",
        "\n",
        "print(f\"Đã lưu {index.ntotal} vector vào FAISS index.\")\n",
        "\n",
        "# LƯU FILE INDEX FAISS\n",
        "faiss.write_index(index, \"./model/medical_symptoms.index\")\n",
        "print(\"Đã lưu file index → ./model/medical_symptoms.index\")\n",
        "\n",
        "# LƯU METADATA (pickle)\n",
        "with open(\"./model/medical_symptoms.pkl\", \"wb\") as f:\n",
        "    pickle.dump(metadata, f)\n",
        "\n",
        "print(\"Đã lưu metadata → ./model/medical_symptoms.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp_VvCJhDKB4",
        "outputId": "116894d9-1d16-444c-fd8c-8d07efd31799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Câu hỏi: Tôi bị đau bụng vùng trên rốn và hay bị ợ chua\n",
            "\n",
            "---- Kết quả ----\n",
            "Top 1 (Khoản cách: 14.3922:)\n",
            "Bệnh: Đau thượng vị\n",
            "Triệu chứng: Tùy vào nguyên nhân gây bệnh mà triệu chứng đau thượng vị khác nhau và sẽ có những triệu chứng đi kè...\n",
            "Top 2 (Khoản cách: 14.5912:)\n",
            "Bệnh: Viêm thực quản trào ngược\n",
            "Triệu chứng: Triệu chứng viêm thực quản trào ngược bao gồm: tại thực quản và ngoài thực quản. Tại thực quảm điển ...\n",
            "Top 3 (Khoản cách: 14.8990:)\n",
            "Bệnh: Đau dạ dày\n",
            "Triệu chứng: Đau dạ dày có thể xuất hiện tại vùng thượng vị ở chính giữa bụng, cũng có thể lệch sang bên trái hoặ...\n",
            "---------------------------------------\n",
            "Câu hỏi: Sốt cao, nổi mẩn đỏ trên da\n",
            "\n",
            "---- Kết quả ----\n",
            "Top 1 (Khoản cách: 17.7181:)\n",
            "Bệnh: Nhiễm liên cầu khuẩn\n",
            "Triệu chứng: Bệnh viêm họng do liên cầu khuẩn: đau họng, đau đầu, đau bụng, sốt cao từ 39 độ kèm theo nổi hạch vù...\n",
            "Top 2 (Khoản cách: 18.3823:)\n",
            "Bệnh: Viêm da cơ địa\n",
            "Triệu chứng: Bệnh viêm da cơ địa có triệu chứng điển hình là da viêm đỏ, tróc vảy, chảy dịch, dày sừng, nứt nẻ, n...\n",
            "Top 3 (Khoản cách: 19.5419:)\n",
            "Bệnh: Viêm khớp liên cầu\n",
            "Triệu chứng: Bệnh nhân viêm khớp liên cầu sẽ có những triệu chứng như: (4)\n",
            "\n",
            "Triệu chứng tại khớp: Người bệnh thườ...\n"
          ]
        }
      ],
      "source": [
        "def search_disease(query, top_k = 3):\n",
        "  query_vector = get_embedding(query)\n",
        "  query_vector = np.array([query_vector]).astype(\"float32\")\n",
        "\n",
        "  D, I = index.search(query_vector, top_k)\n",
        "\n",
        "  print (f\"Câu hỏi: {query}\\n\")\n",
        "  print (\"---- Kết quả ----\")\n",
        "  for i, idx in enumerate(I[0]):\n",
        "    result = metadata[idx]\n",
        "    distance = D[0][i]\n",
        "\n",
        "    print (f\"Top {i+1} (Khoản cách: {distance:.4f}:)\")\n",
        "    print (f\"Bệnh: {result[\"ten_benh\"]}\")\n",
        "    print (f\"Triệu chứng: {result[\"trieu_chung\"][:100]}...\")\n",
        "\n",
        "user_query = \"Tôi bị đau bụng vùng trên rốn và hay bị ợ chua\"\n",
        "search_disease(user_query)\n",
        "\n",
        "print (\"---------------------------------------\")\n",
        "\n",
        "user_query_2 = \"Sốt cao, nổi mẩn đỏ trên da\"\n",
        "search_disease(user_query_2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
